"""A model for working with CDF data.
"""

from __future__ import annotations
import json, warnings, os
from collections import OrderedDict
from typing import Any, List, Dict, Optional

from thefuzz import fuzz
from pydantic import BaseModel, Json
import numpy as np
import pandas as pd

from hectre.consts import (
    CDF_COMPARE_COLS_IGNORE,
    CDF_COMPOUND_KEY_COLS,
    HEADER_ORDER,
    LITERATURE_DATA_HEADERS,
    NO_DATA
)

# Create fields dynamically for LiteratureData and Result models based on definitions.json
# Create method of CDF to create dataframe from LiteratureData and Results

class CDFData(BaseModel, extra='allow'):
    def __init__(self, **kwargs):
        super().__init__()
        for key, val in kwargs.items():
            setattr(self, key, val)


    @classmethod
    def from_dict(cls, values: Dict) -> CDFData:
        return cls(**values)
    

    @classmethod
    def from_dicts(cls, *dicts: Dict[str, Any]) -> CDFData:
        values = OrderedDict()
        for header in HEADER_ORDER:
            for dictionary in dicts:
                if header in dictionary:
                    values[header] = dictionary[header] if NO_DATA not in str(dictionary[header]) else ""
                    break
            if header not in values:
                values[header] = ""
        return cls(**values)


    @classmethod
    def from_json(cls, *json_strs: Json[Dict]) -> CDFData:
        values = {}
        for json_str in json_strs:
            deserialized = json.loads(json_str)
            values.update(deserialized)
        return cls.from_dict(values)
    

class CDF(BaseModel):
    literature_data: Optional[CDFData] = None
    clinical_data: List[CDFData] = []


    def set_literature_data(self, values: CDFData) -> None:
        self.literature_data = values

    
    def add_clinical_data(self, values: CDFData) -> None:
        self.clinical_data.append(values)

    
    def to_df(self) -> pd.DataFrame:
        rows = []
        for result in self.clinical_data:
            row = result.model_dump()
            for key, val in self.literature_data.model_dump().items():
                if str(val) and NO_DATA not in str(val):
                    row[key] = val
            rows.append(row)
        df = pd.DataFrame(rows)
        return df
    

    def save_to_string(self) -> str:
        # Return the full CSV string
        return self.to_df().to_csv(index=False)
    

    def save_to_file(self, name, path=os.path.join(os.path.dirname(__file__), "../../output")) -> None:
        # Save the CDF contents to file
        if not os.path.exists(path):
            os.makedirs(path)
        self.to_df().to_csv(index=False, path_or_buf=os.path.join(path, f"{name}.csv"))

    @staticmethod
    def compare(test_cdf: pd.DataFrame, control_cdf: pd.DataFrame):
        """
        description:
        Compares a test cdf to a control cdf to determine how accurate the test cdf is.

        returns:
        A dictionary with results that describe the accuracy of the test CDF.

        params:
        test_cdf: The cdf we're testing for accuracy (ususally generated by HECTRE)
        control_cdf: The cdf we're comparing to the test cdf to determine accuracy. Considered to be 100% accurate.
        """
        # Suppress performance warning, our volume is low so this will not affect us.
        warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)
        # Cast test and control DataFrame column types to str so we can compare values directly.
        test_cdf = test_cdf.astype(str).replace('nan', '')
        control_cdf = control_cdf.astype(str).replace('nan', '')
        # Drop ingnored columns if they exist.
        for col in CDF_COMPARE_COLS_IGNORE:
            if col in test_cdf.columns:
                test_cdf = test_cdf.drop(columns=[col])
            if col in control_cdf.columns:
                control_cdf = control_cdf.drop(columns=[col])
        # Make sure they have the same columns.
        cols_eq = set(test_cdf.columns) == set(control_cdf.columns)
        if not cols_eq:
            cols = f'Test CDF Columns:\n{test_cdf.columns}\n\nControl CDF Columns:\n{control_cdf.columns}\n\n'
            test_missing = set(HEADER_ORDER) - set(test_cdf.columns)
            control_missing = set(HEADER_ORDER) - set(control_cdf.columns)
            symmetric_diff = set(test_cdf.columns).symmetric_difference(set(control_cdf.columns))
            raise RuntimeError(
                f'The columns in the test and control CDFs are not the same\n\n \
                TEST MISSING COLS:\n{test_missing}\n\n \
                CONTROL MISSING COLS:\n{control_missing}\n\n \
                SYMMETRIC DIFFERENCE:\n{symmetric_diff}'
            )
        test_lit_data = test_cdf.loc[0,LITERATURE_DATA_HEADERS]
        test_clin_data = test_cdf.drop(columns=LITERATURE_DATA_HEADERS)
        # DF of just compound keys.
        test_clin_data_index_vals = test_clin_data[CDF_COMPOUND_KEY_COLS]
        # Transform compound keys to lowercase, remove whitespace, replace hyphens.
        test_clin_data_index_vals = test_clin_data_index_vals.map(lambda x: x.lower()).map(lambda x: x.replace('-', '')).map(lambda x: x.replace(' ', ''))
        # Create the multi-index from CDF_COMPOUND_KEY_COLS.
        test_clin_data = test_clin_data.set_index([np.array(l) for l in test_clin_data_index_vals.T.values])
        test_clin_data = test_clin_data.rename_axis(index=CDF_COMPOUND_KEY_COLS)
        # Add an integer primary key.
        test_clin_data = test_clin_data.assign(primary_key=range(test_clin_data.shape[0])).set_index('primary_key', append=True)
        # Confrol CDF (considered 100% accurate)
        control_lit_data = control_cdf.loc[0,LITERATURE_DATA_HEADERS]
        control_clin_data = control_cdf.drop(columns=LITERATURE_DATA_HEADERS)
        # DF of just compound keys.
        control_clin_data_index_vals = control_clin_data[CDF_COMPOUND_KEY_COLS]
        # Transform compound keys to lowercase, remove whitespace, replace hyphens.
        control_clin_data_index_vals = control_clin_data_index_vals.map(lambda x: x.lower()).map(lambda x: x.replace('-', '')).map(lambda x: x.replace(' ', ''))
        # Create the multi-index from CDF_COMPOUND_KEY_COLS.
        control_clin_data = control_clin_data.set_index([np.array(l) for l in control_clin_data_index_vals.T.values])
        control_clin_data = control_clin_data.rename_axis(index=CDF_COMPOUND_KEY_COLS)
        # Add an integer primary key.
        control_clin_data = control_clin_data.assign(primary_key=range(control_clin_data.shape[0])).set_index('primary_key', append=True)
        clin_results = CDF.compare_clinical_data(test_clin_data, control_clin_data)
        lit_results = CDF.compare_literature_data(test_lit_data, control_lit_data)
        results = {
            "test_clin_data": test_clin_data,
            "test_lit_data": test_lit_data,
            "control_clin_data": control_clin_data,
            "control_lit_data": control_lit_data,
            "row_matches_clin": clin_results['row_matches'],
            "comp_values_clin": clin_results['comp_values'],
            "row_similarities": clin_results['row_similarities'],
            "comp_values_lit": lit_results['comp_values'],
            "stacked_df": clin_results['stacked_df']
        }
        return results
    
    @staticmethod
    def compare_clinical_data(test_df: pd.DataFrame, control_df: pd.DataFrame):
        """
        description:
        Compares a test dataframe of clinical data to a control dataframe to determine how accurate the test dataframe is.

        returns:
        A dictionary with results that describe the accuracy of the test CDF.

        params:
        test_cdf: The cdf we're testing for accuracy (ususally generated by HECTRE)
        control_cdf: The cdf we're comparing to the test cdf to determine accuracy. Considered to be 100% accurate.
        """
        # Create a DataFrame to hold cell-by-cell equality matrix. Initialize every value to False.
        comp_values = pd.DataFrame(0, columns=control_df.columns, index=control_df.index, dtype='Int64').assign(has_match=0)
        similarity_matrix = CDF.create_similarity_matrix(test_df, control_df)
        match_matrix = CDF.create_match_matrix(similarity_matrix.copy())
        for control_key in match_matrix.index:
            matched_test_key = match_matrix.loc[control_key, 'Matched Test Row']
            if pd.isna(matched_test_key):
                # No match for this control_key.
                continue
            for col, val in control_df.loc[control_key].items():
                comp_values.loc[control_key, col] = fuzz.token_sort_ratio(val, test_df.loc[matched_test_key, col])
            comp_values.loc[control_key, 'has_match'] = 1
        comp_values = comp_values.set_index(['has_match'], append=True)
        stacked_df = CDF.create_stacked_df(match_matrix, test_df, control_df, comp_values.droplevel('has_match'))            
        results = {
            'row_matches': match_matrix,
            'comp_values': comp_values,
            'row_similarities': similarity_matrix,
            'stacked_df': stacked_df
        }
        return results
    
    @staticmethod
    def compare_literature_data(test_s: pd.Series, control_s: pd.Series):
        # Create a DataFrame to hold cell-by-cell equality matrix.
        comp_values = pd.Series(index=test_s.index, dtype='Int64')
        for index_s, val_s in test_s.items():
            comp_values.loc[index_s] = fuzz.token_sort_ratio(val_s, control_s[index_s])
        results = {
            'comp_values': comp_values
        }
        return results

    @staticmethod
    def create_similarity_matrix(test_df: pd.DataFrame, control_df: pd.DataFrame):
        sm = pd.DataFrame(0, index=control_df.index, columns=test_df.index)
        for control_key in sm.index:
            control_keys_compare = control_key[:-1]
            for test_key in sm.columns:
                test_keys_compare = test_key[:-1]
                similarity = fuzz.ratio(''.join(control_keys_compare), ''.join(test_keys_compare))
                sm.loc[control_key, test_key] = similarity
        return sm
    
    @staticmethod
    def create_match_matrix(similarity_matrix: pd.DataFrame):
        mm = pd.DataFrame(None, index=similarity_matrix.index, columns=['Matched Test Row', 'Similarity'])
        mm = mm.astype({'Similarity': 'Int64'})
        print(similarity_matrix)
        while len(similarity_matrix.index) > 0 and len(similarity_matrix.columns) > 0:
            highest_value = similarity_matrix.values.max()
            column = similarity_matrix.max().idxmax()
            index = similarity_matrix[column].idxmax()
            similarity_matrix = similarity_matrix.drop(index, axis=0)
            similarity_matrix = similarity_matrix.drop(column, axis=1)
            mm.loc[index] = {'Matched Test Row': column, 'Similarity': highest_value}
        return mm
    
    def create_stacked_df(match_matrix: pd.DataFrame, test_df: pd.DataFrame, control_df: pd.DataFrame, val_similarity_matrix: pd.DataFrame):
        test_df_wm = test_df.copy().assign(match_key='', sample='test').astype('object')
        control_df_wm = control_df.copy().assign(match_key='', sample='control').astype('object')
        similarity_df_wm = val_similarity_matrix.copy().assign(match_key='', sample='similarity').astype('object')
        for control_key, row in match_matrix.iterrows():
            test_key = row['Matched Test Row']
            if pd.isna(test_key):
                # Has no match.
                continue
            match_key = 'c'+str(control_key[-1])+'t'+str(test_key[-1])
            test_df_wm.loc[test_key, 'match_key'] = match_key
            control_df_wm.loc[control_key, 'match_key'] = match_key
            similarity_df_wm.loc[control_key, 'match_key'] = match_key
        test_df_wm = test_df_wm.set_index(['match_key', 'sample'], append=True)
        control_df_wm = control_df_wm.set_index(['match_key', 'sample'], append=True)
        similarity_df_wm = similarity_df_wm.set_index(['match_key', 'sample'], append=True)
        sample_sort_priorities = {'test': 2, 'control':1, 'similarity':0}
        stacked_df = pd.concat(objs=[test_df_wm, control_df_wm, similarity_df_wm])
        stacked_df['sample_sortby'] = stacked_df.index.to_frame()['sample'].map(sample_sort_priorities)
        stacked_df = stacked_df.set_index(['sample_sortby'], append=True)
        stacked_df = stacked_df.sort_index(level=['match_key', 'sample_sortby'], ascending=False)
        stacked_df = stacked_df.droplevel('sample_sortby')
        stacked_df = stacked_df[~((stacked_df.index.get_level_values('sample') == 'similarity') & (stacked_df.index.get_level_values('match_key') == ''))]
        return stacked_df




